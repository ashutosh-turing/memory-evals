# Memory-Break Orchestrator Configuration
# Copy this file to .env and update with your actual values

# Application Settings
APP_NAME="Memory-Break Orchestrator"
APP_VERSION="0.1.0"
DEBUG=false
HOST=127.0.0.1
PORT=8000

# Database Configuration
DATABASE_URL=postgresql://user:password@localhost:5432/memory_break_db

# Redis Configuration
REDIS_URL=redis://localhost:6379/0

# File Storage
RUN_ROOT=storage
MAX_FILES_PER_TASK=50

# Agent CLI Binaries
IFLOW_BIN=iflow
CLAUDE_BIN=claude
GEMINI_BIN=gemini

# iFlow Configuration (Required for iFlow agent)
IFLOW_API_KEY=your_iflow_api_key_here
IFLOW_BASE_URL=https://apis.iflow.cn/v1
IFLOW_MODEL_NAME=qwen3-coder-plus

# Claude Configuration
CLAUDE_MODEL=claude-sonnet-4-5-20250929

# Gemini Configuration
GEMINI_MODEL=gemini-2.5-pro

# API Keys for LLM Judge and Prompt Generation (Required for LLM features)
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here
GOOGLE_API_KEY=your_google_api_key_here

# Security
ALLOWED_ORIGINS=["http://localhost:3000","http://localhost:8000","http://127.0.0.1:8000"]

# Task Processing Timeouts
TASK_TIMEOUT_SECONDS=7200
AGENT_SESSION_TIMEOUT=3600

# Agent Token Limits (for fair comparison)
MAX_CONTEXT_TOKENS=200000
MAX_TURNS=100

# Compression Detection Thresholds
COMPRESSION_THRESHOLD_LOW=30
COMPRESSION_JUMP_THRESHOLD=30

# Judge Configuration
DEFAULT_JUDGE=llm
JUDGE_MODEL=gpt-4o

# Prompt Generation Configuration
USE_GPT_PROMPTS=true
PROMPT_MODEL=gpt-4o
PROMPT_TEMPERATURE=1.0
PROMPT_MAX_TOKENS=4000